{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Out-of-Core MOE for Multi-Task RL\n",
    "\n",
    "Training notebook for the ooc_moe project. Clones from GitHub for easy iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch numpy gymnasium opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "id": "upload",
    "outputId": "4e592432-d50b-424c-e72e-dac7d028bbb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning https://github.com/YOUR_USERNAME/ooc_moe.git...\n",
      "Cloning into 'ooc_moe'...\n",
      "fatal: could not read Username for 'https://github.com': No such device or address\n",
      "Done!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Clone repo from GitHub (edit REPO_URL to match your repository)\n",
    "import os\n",
    "\n",
    "REPO_URL = \"https://github.com/RespectableGlioma/ooc_moe.git\"  # <-- Change this!\n",
    "BRANCH = \"main\"  # Change if using a different branch\n",
    "\n",
    "if not os.path.exists('ooc_moe'):\n",
    "    print(f'Cloning {REPO_URL}...')\n",
    "    !git clone --branch {BRANCH} --depth 1 {REPO_URL}\n",
    "    print('Done!')\n",
    "else:\n",
    "    print('Repo exists, pulling latest changes...')\n",
    "    !cd ooc_moe && git pull\n",
    "    print('Updated!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imports",
    "outputId": "af227eb4-d642-4a9a-fcf5-03b474170b2b"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Setup imports\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add repo root to path (where ooc_moe package lives)\n",
    "REPO_PATH = '/content/ooc_moe'\n",
    "if os.path.exists(REPO_PATH):\n",
    "    sys.path.insert(0, REPO_PATH)\n",
    "else:\n",
    "    sys.path.insert(0, '.')  # Fallback for local dev\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from collections import defaultdict, deque\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from ooc_moe.models.moe_agent import MoERLAgent, MoERLAgentConfig\n",
    "from ooc_moe.envs.atari_wrappers import create_dummy_envs\n",
    "from ooc_moe.core.env_detector import EnvironmentDetectorTrainer\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'PyTorch {torch.__version__} on {device}')\n",
    "if device == 'cuda':\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "config",
    "outputId": "d8034509-012e-42ba-d586-a6017835fc8b"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'num_experts': 64,\n",
    "    'expert_dim': 128,\n",
    "    'expert_hidden_dim': 256,\n",
    "    'num_layers': 2,\n",
    "    'num_heads': 4,\n",
    "    'top_k': 2,\n",
    "    'context_len': 8,\n",
    "    'hbm_capacity': 16,\n",
    "    'dram_capacity': 32,\n",
    "    'num_games': 5,\n",
    "    'steps_per_game': 1000,\n",
    "    'lr': 1e-4,\n",
    "    # Specialization parameters\n",
    "    'aux_loss_weight': 0.001,  # Reduced from 0.01 to allow specialization\n",
    "    'detector_lr': 1e-3,       # Learning rate for env detector\n",
    "    'detector_train_freq': 10, # Train detector every N steps\n",
    "}\n",
    "print('Config:', CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "create_agent",
    "outputId": "40f52c6a-7383-4282-c32c-a3dcf05e7974"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create agent, environments, and detector trainer\n",
    "config = MoERLAgentConfig(\n",
    "    obs_shape=(1, 84, 84),\n",
    "    num_actions=18,\n",
    "    num_envs=CONFIG['num_games'],\n",
    "    frame_stack=4,\n",
    "    num_experts=CONFIG['num_experts'],\n",
    "    expert_dim=CONFIG['expert_dim'],\n",
    "    expert_hidden_dim=CONFIG['expert_hidden_dim'],\n",
    "    num_layers=CONFIG['num_layers'],\n",
    "    num_heads=CONFIG['num_heads'],\n",
    "    top_k=CONFIG['top_k'],\n",
    "    context_len=CONFIG['context_len'],\n",
    "    hbm_capacity=CONFIG['hbm_capacity'],\n",
    "    dram_capacity=CONFIG['dram_capacity'],\n",
    ")\n",
    "\n",
    "agent = config.create_agent(device)\n",
    "envs, env_names = create_dummy_envs(CONFIG['num_games'])\n",
    "optimizer = torch.optim.Adam(agent.parameters(), lr=CONFIG['lr'])\n",
    "\n",
    "# Create detector trainer for learning game->expert mappings\n",
    "detector_trainer = EnvironmentDetectorTrainer(\n",
    "    detector=agent.env_detector,\n",
    "    lr=CONFIG['detector_lr'],\n",
    "    env_loss_weight=1.0,\n",
    "    expert_loss_weight=1.0,\n",
    ")\n",
    "\n",
    "print(f'Agent created with {config.estimate_parameter_count()[\"total\"]:,} params')\n",
    "print(f'Environments: {env_names}')\n",
    "print(f'Detector trainer ready (trains every {CONFIG[\"detector_train_freq\"]} steps)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "training",
    "outputId": "1208f755-f11e-4bd7-aace-1021ef445c1e"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Training loop with detector training for specialization\n",
    "results = {\n",
    "    'cache_history': [],\n",
    "    'expert_usage': defaultdict(lambda: defaultdict(int)),\n",
    "    'rewards': defaultdict(list),\n",
    "    'losses': [],\n",
    "    'detector_losses': [],\n",
    "    'prefetch_accuracy': [],\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "global_step = 0\n",
    "\n",
    "for game_id, (env, name) in enumerate(zip(envs, env_names)):\n",
    "    print(f'\\nTraining on {name} ({game_id+1}/{len(envs)})...')\n",
    "\n",
    "    obs, _ = env.reset()\n",
    "    obs_buffer = deque(\n",
    "        [torch.from_numpy(obs.astype(np.float32) / 255.0) for _ in range(config.context_len)],\n",
    "        maxlen=config.context_len\n",
    "    )\n",
    "\n",
    "    episode_reward = 0\n",
    "    episode_count = 0\n",
    "\n",
    "    for step in range(CONFIG['steps_per_game']):\n",
    "        global_step += 1\n",
    "\n",
    "        # Build context\n",
    "        context = torch.stack(list(obs_buffer), dim=0).unsqueeze(0).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        agent.train()\n",
    "        output = agent(context, env_id=game_id, prefetch=True)\n",
    "\n",
    "        # Track metrics\n",
    "        for eid in output.expert_ids:\n",
    "            results['expert_usage'][game_id][eid] += 1\n",
    "        results['cache_history'].append(output.cache_stats['hit_rate'])\n",
    "\n",
    "        # Store sample for detector training\n",
    "        last_obs = context[:, -1].detach()  # [1, C*frame_stack, H, W]\n",
    "        detector_trainer.store_sample(\n",
    "            obs=last_obs.squeeze(0),  # [C*frame_stack, H, W]\n",
    "            env_id=game_id,\n",
    "            accessed_experts=output.expert_ids,\n",
    "        )\n",
    "\n",
    "        # Train detector periodically\n",
    "        if global_step % CONFIG['detector_train_freq'] == 0:\n",
    "            det_losses = detector_trainer.train_step(batch_size=32)\n",
    "            results['detector_losses'].append(det_losses['total_loss'])\n",
    "\n",
    "            # Track prefetch accuracy occasionally\n",
    "            if global_step % (CONFIG['detector_train_freq'] * 10) == 0:\n",
    "                accuracy = detector_trainer.compute_prefetch_accuracy(recent_n=50)\n",
    "                results['prefetch_accuracy'].append(accuracy['f1'])\n",
    "\n",
    "        # Sample action\n",
    "        probs = F.softmax(output.action_logits, dim=-1)\n",
    "        action = torch.multinomial(probs, 1).item()\n",
    "\n",
    "        # Environment step\n",
    "        next_obs, reward, done, _, _ = env.step(action)\n",
    "        episode_reward += reward\n",
    "\n",
    "        # Policy gradient update with REDUCED aux loss for specialization\n",
    "        log_prob = torch.log(probs[0, action] + 1e-8)\n",
    "        loss = -log_prob * reward + CONFIG['aux_loss_weight'] * output.aux_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(agent.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        results['losses'].append(loss.item())\n",
    "\n",
    "        # Update observation buffer\n",
    "        obs_buffer.append(torch.from_numpy(next_obs.astype(np.float32) / 255.0))\n",
    "\n",
    "        if done:\n",
    "            results['rewards'][game_id].append(episode_reward)\n",
    "            episode_reward = 0\n",
    "            episode_count += 1\n",
    "            obs, _ = env.reset()\n",
    "            obs_buffer = deque(\n",
    "                [torch.from_numpy(obs.astype(np.float32) / 255.0) for _ in range(config.context_len)],\n",
    "                maxlen=config.context_len\n",
    "            )\n",
    "\n",
    "    # Log progress\n",
    "    recent_cache = results['cache_history'][-CONFIG['steps_per_game']:]\n",
    "    avg_reward = np.mean(results['rewards'][game_id]) if results['rewards'][game_id] else 0\n",
    "\n",
    "    # Compute specialization metric for this game\n",
    "    usage = results['expert_usage'][game_id]\n",
    "    total_usage = sum(usage.values())\n",
    "    top_expert_pct = max(usage.values()) / total_usage if total_usage > 0 else 0\n",
    "\n",
    "    print(f'  Episodes: {episode_count}, Avg reward: {avg_reward:.2f}')\n",
    "    print(f'  Cache hit rate: {np.mean(recent_cache):.2%}')\n",
    "    print(f'  Unique experts: {len(usage)}, Top expert: {top_expert_pct:.1%}')\n",
    "    if results['prefetch_accuracy']:\n",
    "        print(f'  Detector prefetch F1: {results[\"prefetch_accuracy\"][-1]:.2%}')\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f'\\nTraining complete in {elapsed:.1f}s')\n",
    "\n",
    "# Cleanup\n",
    "agent.expert_store.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 899
    },
    "id": "visualize",
    "outputId": "4b320b45-cd37-45c5-916b-b0c77a3174f0"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Results visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# Cache hit rate\n",
    "ax = axes[0, 0]\n",
    "ax.plot(results['cache_history'], alpha=0.3, label='Raw')\n",
    "window = 100\n",
    "smoothed = np.convolve(results['cache_history'], np.ones(window)/window, mode='valid')\n",
    "ax.plot(range(window-1, len(results['cache_history'])), smoothed, 'r-', lw=2, label=f'Smoothed (w={window})')\n",
    "ax.axhline(np.mean(results['cache_history']), color='g', linestyle='--', label=f'Mean: {np.mean(results[\"cache_history\"]):.2%}')\n",
    "for i in range(1, CONFIG['num_games']):\n",
    "    ax.axvline(i * CONFIG['steps_per_game'], color='gray', linestyle=':', alpha=0.5)\n",
    "ax.set_xlabel('Step')\n",
    "ax.set_ylabel('Cache Hit Rate')\n",
    "ax.set_title('Cache Performance Over Training')\n",
    "ax.legend()\n",
    "\n",
    "# Expert usage heatmap (should show distinct bands with specialization)\n",
    "ax = axes[0, 1]\n",
    "usage_matrix = np.zeros((CONFIG['num_games'], CONFIG['num_experts']))\n",
    "for gid, usage in results['expert_usage'].items():\n",
    "    for eid, count in usage.items():\n",
    "        if eid < CONFIG['num_experts']:\n",
    "            usage_matrix[gid, eid] = count\n",
    "usage_matrix = usage_matrix / (usage_matrix.sum(axis=1, keepdims=True) + 1e-8)\n",
    "im = ax.imshow(usage_matrix, aspect='auto', cmap='hot')\n",
    "ax.set_xlabel('Expert ID')\n",
    "ax.set_ylabel('Game ID')\n",
    "ax.set_title('Expert Usage by Game (Should Show Distinct Bands)')\n",
    "plt.colorbar(im, ax=ax)\n",
    "\n",
    "# Episode rewards\n",
    "ax = axes[0, 2]\n",
    "for gid, rewards in results['rewards'].items():\n",
    "    if rewards:\n",
    "        ax.plot(rewards, label=f'Game {gid}', alpha=0.7)\n",
    "ax.set_xlabel('Episode')\n",
    "ax.set_ylabel('Reward')\n",
    "ax.set_title('Episode Rewards')\n",
    "ax.legend()\n",
    "\n",
    "# Expert overlap matrix\n",
    "ax = axes[1, 0]\n",
    "def get_top_k(usage_dict, k=10):\n",
    "    return set(e for e, _ in sorted(usage_dict.items(), key=lambda x: x[1], reverse=True)[:k])\n",
    "\n",
    "overlap_matrix = np.zeros((CONFIG['num_games'], CONFIG['num_games']))\n",
    "for i in range(CONFIG['num_games']):\n",
    "    for j in range(CONFIG['num_games']):\n",
    "        top_i = get_top_k(results['expert_usage'][i])\n",
    "        top_j = get_top_k(results['expert_usage'][j])\n",
    "        overlap_matrix[i, j] = len(top_i & top_j) / 10\n",
    "\n",
    "im = ax.imshow(overlap_matrix, cmap='Blues', vmin=0, vmax=1)\n",
    "ax.set_xlabel('Game')\n",
    "ax.set_ylabel('Game')\n",
    "ax.set_title('Expert Overlap (Top 10) - Lower = Better Specialization')\n",
    "for i in range(CONFIG['num_games']):\n",
    "    for j in range(CONFIG['num_games']):\n",
    "        ax.text(j, i, f'{overlap_matrix[i,j]:.0%}', ha='center', va='center')\n",
    "plt.colorbar(im, ax=ax)\n",
    "\n",
    "# Detector loss\n",
    "ax = axes[1, 1]\n",
    "if results['detector_losses']:\n",
    "    ax.plot(results['detector_losses'], alpha=0.7)\n",
    "    if len(results['detector_losses']) > 50:\n",
    "        window = 50\n",
    "        smoothed = np.convolve(results['detector_losses'], np.ones(window)/window, mode='valid')\n",
    "        ax.plot(range(window-1, len(results['detector_losses'])), smoothed, 'r-', lw=2, label='Smoothed')\n",
    "        ax.legend()\n",
    "ax.set_xlabel('Training Step (detector)')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Detector Training Loss')\n",
    "\n",
    "# Prefetch accuracy\n",
    "ax = axes[1, 2]\n",
    "if results['prefetch_accuracy']:\n",
    "    ax.plot(results['prefetch_accuracy'], 'b-o', markersize=4)\n",
    "    ax.axhline(np.mean(results['prefetch_accuracy']), color='r', linestyle='--', \n",
    "               label=f'Mean: {np.mean(results[\"prefetch_accuracy\"]):.2%}')\n",
    "    ax.legend()\n",
    "ax.set_xlabel('Checkpoint')\n",
    "ax.set_ylabel('Prefetch F1 Score')\n",
    "ax.set_title('Detector Prefetch Accuracy')\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_results.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "summary"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Summary statistics\n",
    "print('=' * 60)\n",
    "print('TRAINING SUMMARY')\n",
    "print('=' * 60)\n",
    "\n",
    "print(f'\\nOverall cache hit rate: {np.mean(results[\"cache_history\"]):.2%}')\n",
    "print(f'Final cache hit rate: {np.mean(results[\"cache_history\"][-500:]):.2%}')\n",
    "\n",
    "# Detector performance\n",
    "if results['prefetch_accuracy']:\n",
    "    print(f'\\nDetector prefetch F1 (final): {results[\"prefetch_accuracy\"][-1]:.2%}')\n",
    "    print(f'Detector prefetch F1 (mean): {np.mean(results[\"prefetch_accuracy\"]):.2%}')\n",
    "\n",
    "print('\\nPer-game statistics:')\n",
    "for gid in range(CONFIG['num_games']):\n",
    "    usage = results['expert_usage'][gid]\n",
    "    rewards = results['rewards'][gid]\n",
    "    top5 = sorted(usage.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    total = sum(usage.values())\n",
    "    print(f'\\n  Game {gid}:')\n",
    "    print(f'    Unique experts: {len(usage)}')\n",
    "    print(f'    Top 5 experts: {[(e, f\"{c/total:.1%}\") for e, c in top5]}')\n",
    "    print(f'    Avg episode reward: {np.mean(rewards) if rewards else 0:.2f}')\n",
    "\n",
    "print('\\nExpert specialization (low overlap = good specialization):')\n",
    "overlaps = []\n",
    "for i in range(CONFIG['num_games']):\n",
    "    for j in range(i+1, CONFIG['num_games']):\n",
    "        top_i = get_top_k(results['expert_usage'][i])\n",
    "        top_j = get_top_k(results['expert_usage'][j])\n",
    "        overlap = len(top_i & top_j)\n",
    "        overlaps.append(overlap)\n",
    "        print(f'  Game {i} vs {j}: {overlap}/10 experts overlap')\n",
    "print(f'  Average overlap: {np.mean(overlaps):.1f}/10')\n",
    "\n",
    "# Expected partitions (based on initialization)\n",
    "print('\\n' + '=' * 60)\n",
    "print('EXPECTED EXPERT PARTITIONS (from env_expert_bias initialization)')\n",
    "print('=' * 60)\n",
    "experts_per_env = CONFIG['num_experts'] // CONFIG['num_games']\n",
    "for gid in range(CONFIG['num_games']):\n",
    "    start = gid * experts_per_env\n",
    "    end = start + experts_per_env if gid < CONFIG['num_games'] - 1 else CONFIG['num_experts']\n",
    "    print(f'  Game {gid}: Experts {start}-{end-1}')\n",
    "print('\\nIf specialization is working, each game should predominantly use its partition!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "import json\n",
    "from google.colab import files\n",
    "\n",
    "save_data = {\n",
    "    'config': CONFIG,\n",
    "    'cache_history': results['cache_history'],\n",
    "    'expert_usage': {int(k): dict(v) for k, v in results['expert_usage'].items()},\n",
    "    'rewards': {int(k): list(v) for k, v in results['rewards'].items()},\n",
    "    'summary': {\n",
    "        'mean_cache_hit': float(np.mean(results['cache_history'])),\n",
    "        'final_cache_hit': float(np.mean(results['cache_history'][-500:])),\n",
    "        'avg_overlap': float(np.mean(overlaps)),\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(save_data, f, indent=2)\n",
    "\n",
    "print('Results saved to results.json')\n",
    "files.download('results.json')\n",
    "files.download('training_results.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q3HBlX2VP8t_"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
